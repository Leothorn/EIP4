Architechture of Resnet 18



Learning rate:  0.001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 16, 128)  18944       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 16, 128)  512         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 16, 128)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
res0a_branch2a (SeparableConv2D (None, 8, 8, 128)    17664       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 8, 8, 128)    512         res0a_branch2a[0][0]             
__________________________________________________________________________________________________
separable_conv2d_2 (SeparableCo (None, 8, 8, 128)    16640       activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 8, 128)    0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 8, 128)    512         separable_conv2d_2[0][0]         
__________________________________________________________________________________________________
separable_conv2d_1 (SeparableCo (None, 8, 8, 128)    17664       activation_2[0][0]               
__________________________________________________________________________________________________
add_1 (Add)                     (None, 8, 8, 128)    0           batch_normalization_3[0][0]      
                                                                 separable_conv2d_1[0][0]         
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 8, 128)    512         add_1[0][0]                      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 8, 8, 128)    0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
separable_conv2d_3 (SeparableCo (None, 8, 8, 128)    17664       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 8, 128)    512         separable_conv2d_3[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 8, 8, 128)    0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
separable_conv2d_4 (SeparableCo (None, 8, 8, 128)    17664       activation_4[0][0]               
__________________________________________________________________________________________________
add_2 (Add)                     (None, 8, 8, 128)    0           add_1[0][0]                      
                                                                 separable_conv2d_4[0][0]         
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 8, 8, 128)    512         add_2[0][0]                      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 8, 8, 128)    0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
separable_conv2d_5 (SeparableCo (None, 4, 4, 256)    34176       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        separable_conv2d_5[0][0]         
__________________________________________________________________________________________________
separable_conv2d_7 (SeparableCo (None, 4, 4, 256)    33152       add_2[0][0]                      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 4, 4, 256)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 4, 4, 256)    1024        separable_conv2d_7[0][0]         
__________________________________________________________________________________________________
separable_conv2d_6 (SeparableCo (None, 4, 4, 256)    68096       activation_6[0][0]               
__________________________________________________________________________________________________
add_3 (Add)                     (None, 4, 4, 256)    0           batch_normalization_8[0][0]      
                                                                 separable_conv2d_6[0][0]         
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 4, 4, 256)    1024        add_3[0][0]                      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 4, 4, 256)    0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
separable_conv2d_8 (SeparableCo (None, 4, 4, 256)    68096       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 4, 4, 256)    1024        separable_conv2d_8[0][0]         
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 4, 4, 256)    0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
separable_conv2d_9 (SeparableCo (None, 4, 4, 256)    68096       activation_8[0][0]               
__________________________________________________________________________________________________
add_4 (Add)                     (None, 4, 4, 256)    0           add_3[0][0]                      
                                                                 separable_conv2d_9[0][0]         
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        add_4[0][0]                      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 4, 4, 256)    0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
separable_conv2d_10 (SeparableC (None, 2, 2, 512)    133888      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_10[0][0]        
__________________________________________________________________________________________________
separable_conv2d_12 (SeparableC (None, 2, 2, 512)    131840      add_4[0][0]                      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 2, 2, 512)    0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_12[0][0]        
__________________________________________________________________________________________________
separable_conv2d_11 (SeparableC (None, 2, 2, 512)    267264      activation_10[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 2, 2, 512)    0           batch_normalization_13[0][0]     
                                                                 separable_conv2d_11[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 2, 2, 512)    2048        add_5[0][0]                      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 2, 2, 512)    0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
separable_conv2d_13 (SeparableC (None, 2, 2, 512)    267264      activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_13[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 2, 2, 512)    0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
separable_conv2d_14 (SeparableC (None, 2, 2, 512)    267264      activation_12[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 2, 2, 512)    0           add_5[0][0]                      
                                                                 separable_conv2d_14[0][0]        
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 2, 2, 512)    2048        add_6[0][0]                      
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 2, 2, 512)    0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
separable_conv2d_15 (SeparableC (None, 1, 1, 1024)   529920      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_15[0][0]        
__________________________________________________________________________________________________
separable_conv2d_17 (SeparableC (None, 1, 1, 1024)   525824      add_6[0][0]                      
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_17[0][0]        
__________________________________________________________________________________________________
separable_conv2d_16 (SeparableC (None, 1, 1, 1024)   1058816     activation_14[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 1, 1, 1024)   0           batch_normalization_18[0][0]     
                                                                 separable_conv2d_16[0][0]        
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 1, 1, 1024)   4096        add_7[0][0]                      
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
separable_conv2d_18 (SeparableC (None, 1, 1, 1024)   1058816     activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_18[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
separable_conv2d_19 (SeparableC (None, 1, 1, 1024)   1058816     activation_16[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 1, 1, 1024)   0           add_7[0][0]                      
                                                                 separable_conv2d_19[0][0]        
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 1, 1, 1024)   4096        add_8[0][0]                      
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 1024)         0           activation_17[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           10250       global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 5,726,730
Trainable params: 5,707,274
Non-trainable params: 19,456
__________________________________________________________________________________________________



Using real-time data augmentation.
Epoch 1/50
Learning rate:  0.001
391/390 [==============================] - 39s 100ms/step - loss: 1.6486 - acc: 0.4109 - val_loss: 1.4207 - val_acc: 0.5101

Epoch 00001: val_acc improved from -inf to 0.51010, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.001.h5
Epoch 2/50
Learning rate:  0.001
391/390 [==============================] - 34s 88ms/step - loss: 1.2826 - acc: 0.5476 - val_loss: 1.2937 - val_acc: 0.5651

Epoch 00002: val_acc improved from 0.51010 to 0.56510, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.002.h5
Epoch 3/50
Learning rate:  0.001
391/390 [==============================] - 34s 88ms/step - loss: 1.0851 - acc: 0.6207 - val_loss: 1.0691 - val_acc: 0.6461

Epoch 00003: val_acc improved from 0.56510 to 0.64610, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.003.h5
Epoch 4/50
Learning rate:  0.001
391/390 [==============================] - 35s 88ms/step - loss: 0.9730 - acc: 0.6612 - val_loss: 0.8551 - val_acc: 0.7091

Epoch 00004: val_acc improved from 0.64610 to 0.70910, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.004.h5
Epoch 5/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.8856 - acc: 0.6933 - val_loss: 0.8750 - val_acc: 0.7127

Epoch 00005: val_acc improved from 0.70910 to 0.71270, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.005.h5
Epoch 6/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.8152 - acc: 0.7185 - val_loss: 0.7742 - val_acc: 0.7431

Epoch 00006: val_acc improved from 0.71270 to 0.74310, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.006.h5
Epoch 7/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.7573 - acc: 0.7396 - val_loss: 0.8242 - val_acc: 0.7335

Epoch 00007: val_acc did not improve from 0.74310
Epoch 8/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.7140 - acc: 0.7546 - val_loss: 0.8152 - val_acc: 0.7413

Epoch 00008: val_acc did not improve from 0.74310
Epoch 9/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.6698 - acc: 0.7715 - val_loss: 0.6223 - val_acc: 0.7975

Epoch 00009: val_acc improved from 0.74310 to 0.79750, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.009.h5
Epoch 10/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.6359 - acc: 0.7835 - val_loss: 0.7165 - val_acc: 0.7658

Epoch 00010: val_acc did not improve from 0.79750
Epoch 11/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5994 - acc: 0.7947 - val_loss: 0.6034 - val_acc: 0.8038

Epoch 00011: val_acc improved from 0.79750 to 0.80380, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.011.h5
Epoch 12/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5738 - acc: 0.8055 - val_loss: 0.5944 - val_acc: 0.8114

Epoch 00012: val_acc improved from 0.80380 to 0.81140, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.012.h5
Epoch 13/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5498 - acc: 0.8124 - val_loss: 0.6251 - val_acc: 0.8009

Epoch 00013: val_acc did not improve from 0.81140
Epoch 14/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5200 - acc: 0.8233 - val_loss: 0.5515 - val_acc: 0.8220

Epoch 00014: val_acc improved from 0.81140 to 0.82200, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.014.h5
Epoch 15/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5080 - acc: 0.8269 - val_loss: 0.6137 - val_acc: 0.8087

Epoch 00015: val_acc did not improve from 0.82200
Epoch 16/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.4801 - acc: 0.8367 - val_loss: 0.6028 - val_acc: 0.8105

Epoch 00016: val_acc did not improve from 0.82200
Epoch 17/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.4618 - acc: 0.8419 - val_loss: 0.5482 - val_acc: 0.8247

Epoch 00017: val_acc improved from 0.82200 to 0.82470, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.017.h5
Epoch 18/50
Learning rate:  0.001
391/390 [==============================] - 35s 90ms/step - loss: 0.4504 - acc: 0.8464 - val_loss: 0.5295 - val_acc: 0.8295

Epoch 00018: val_acc improved from 0.82470 to 0.82950, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.018.h5
Epoch 19/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.4297 - acc: 0.8545 - val_loss: 0.5665 - val_acc: 0.8182

Epoch 00019: val_acc did not improve from 0.82950
Epoch 20/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.4161 - acc: 0.8580 - val_loss: 0.6296 - val_acc: 0.8138

Epoch 00020: val_acc did not improve from 0.82950
Epoch 21/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3987 - acc: 0.8668 - val_loss: 0.5347 - val_acc: 0.8336

Epoch 00021: val_acc improved from 0.82950 to 0.83360, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.021.h5
Epoch 22/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3938 - acc: 0.8658 - val_loss: 0.5264 - val_acc: 0.8375

Epoch 00022: val_acc improved from 0.83360 to 0.83750, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.022.h5
Epoch 23/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3777 - acc: 0.8715 - val_loss: 0.5548 - val_acc: 0.8383

Epoch 00023: val_acc improved from 0.83750 to 0.83830, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.023.h5
Epoch 24/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3612 - acc: 0.8774 - val_loss: 0.5206 - val_acc: 0.8387

Epoch 00024: val_acc improved from 0.83830 to 0.83870, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.024.h5
Epoch 25/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3531 - acc: 0.8803 - val_loss: 0.5256 - val_acc: 0.8412

Epoch 00025: val_acc improved from 0.83870 to 0.84120, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.025.h5
Epoch 26/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3421 - acc: 0.8828 - val_loss: 0.5233 - val_acc: 0.8446

Epoch 00026: val_acc improved from 0.84120 to 0.84460, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.026.h5
Epoch 27/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3295 - acc: 0.8880 - val_loss: 0.5876 - val_acc: 0.8199

Epoch 00027: val_acc did not improve from 0.84460
Epoch 28/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3240 - acc: 0.8896 - val_loss: 0.5059 - val_acc: 0.8521

Epoch 00028: val_acc improved from 0.84460 to 0.85210, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.028.h5
Epoch 29/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3123 - acc: 0.8948 - val_loss: 0.5118 - val_acc: 0.8516

Epoch 00029: val_acc did not improve from 0.85210
Epoch 30/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.3070 - acc: 0.8953 - val_loss: 0.6075 - val_acc: 0.8297

Epoch 00030: val_acc did not improve from 0.85210
Epoch 31/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2956 - acc: 0.8995 - val_loss: 0.5007 - val_acc: 0.8533

Epoch 00031: val_acc improved from 0.85210 to 0.85330, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.031.h5
Epoch 32/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2885 - acc: 0.9028 - val_loss: 0.4759 - val_acc: 0.8610

Epoch 00032: val_acc improved from 0.85330 to 0.86100, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.032.h5
Epoch 33/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2769 - acc: 0.9074 - val_loss: 0.5262 - val_acc: 0.8485

Epoch 00033: val_acc did not improve from 0.86100
Epoch 34/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2726 - acc: 0.9072 - val_loss: 0.5708 - val_acc: 0.8453

Epoch 00034: val_acc did not improve from 0.86100
Epoch 35/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2689 - acc: 0.9091 - val_loss: 0.5999 - val_acc: 0.8360

Epoch 00035: val_acc did not improve from 0.86100
Epoch 36/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.2541 - acc: 0.9148 - val_loss: 0.5055 - val_acc: 0.8612

Epoch 00036: val_acc improved from 0.86100 to 0.86120, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.036.h5
Epoch 37/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.1982 - acc: 0.9368 - val_loss: 0.4085 - val_acc: 0.8829

Epoch 00037: val_acc improved from 0.86120 to 0.88290, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.037.h5
Epoch 38/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.1751 - acc: 0.9455 - val_loss: 0.4061 - val_acc: 0.8852

Epoch 00038: val_acc improved from 0.88290 to 0.88520, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.038.h5
Epoch 39/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.1664 - acc: 0.9471 - val_loss: 0.4029 - val_acc: 0.8874

Epoch 00039: val_acc improved from 0.88520 to 0.88740, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.039.h5
Epoch 40/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.1559 - acc: 0.9507 - val_loss: 0.4076 - val_acc: 0.8864

Epoch 00040: val_acc did not improve from 0.88740
Epoch 41/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.1575 - acc: 0.9502 - val_loss: 0.4134 - val_acc: 0.8861

Epoch 00041: val_acc did not improve from 0.88740
Epoch 42/50
Learning rate:  0.00015
391/390 [==============================] - 35s 89ms/step - loss: 0.1503 - acc: 0.9530 - val_loss: 0.4089 - val_acc: 0.8896

Epoch 00042: val_acc improved from 0.88740 to 0.88960, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.042.h5
Epoch 43/50
Learning rate:  0.00015
391/390 [==============================] - 35s 89ms/step - loss: 0.1461 - acc: 0.9534 - val_loss: 0.4146 - val_acc: 0.8870

Epoch 00043: val_acc did not improve from 0.88960
Epoch 44/50
Learning rate:  0.00015
391/390 [==============================] - 35s 89ms/step - loss: 0.1401 - acc: 0.9556 - val_loss: 0.4124 - val_acc: 0.8890

Epoch 00044: val_acc did not improve from 0.88960
Epoch 45/50
Learning rate:  0.00015
391/390 [==============================] - 35s 89ms/step - loss: 0.1357 - acc: 0.9576 - val_loss: 0.4283 - val_acc: 0.8870

Epoch 00045: val_acc did not improve from 0.88960
Epoch 46/50
Learning rate:  0.00015
391/390 [==============================] - 35s 89ms/step - loss: 0.1357 - acc: 0.9583 - val_loss: 0.4477 - val_acc: 0.8849

Epoch 00046: val_acc did not improve from 0.88960
Epoch 47/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.1312 - acc: 0.9596 - val_loss: 0.4245 - val_acc: 0.8887

Epoch 00047: val_acc did not improve from 0.88960
Epoch 48/50
Learning rate:  1e-05
391/390 [==============================] - 35s 90ms/step - loss: 0.1276 - acc: 0.9599 - val_loss: 0.4194 - val_acc: 0.8902

Epoch 00048: val_acc improved from 0.88960 to 0.89020, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.048.h5
Epoch 49/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.1283 - acc: 0.9611 - val_loss: 0.4207 - val_acc: 0.8905

Epoch 00049: val_acc improved from 0.89020 to 0.89050, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.049.h5
Epoch 50/50
Learning rate:  1e-05
391/390 [==============================] - 35s 90ms/step - loss: 0.1263 - acc: 0.9614 - val_loss: 0.4162 - val_acc: 0.8918

Epoch 00050: val_acc improved from 0.89050 to 0.89180, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.050.h5
