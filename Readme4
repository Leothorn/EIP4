Architechture of Resnet 18



Learning rate:  0.001
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 16, 128)  18944       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 16, 128)  512         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 16, 128)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
res0a_branch2a (SeparableConv2D (None, 8, 8, 128)    17664       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 8, 8, 128)    512         res0a_branch2a[0][0]             
__________________________________________________________________________________________________
separable_conv2d_2 (SeparableCo (None, 8, 8, 128)    16640       activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 8, 128)    0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 8, 128)    512         separable_conv2d_2[0][0]         
__________________________________________________________________________________________________
separable_conv2d_1 (SeparableCo (None, 8, 8, 128)    17664       activation_2[0][0]               
__________________________________________________________________________________________________
add_1 (Add)                     (None, 8, 8, 128)    0           batch_normalization_3[0][0]      
                                                                 separable_conv2d_1[0][0]         
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 8, 128)    512         add_1[0][0]                      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 8, 8, 128)    0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
separable_conv2d_3 (SeparableCo (None, 8, 8, 128)    17664       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 8, 128)    512         separable_conv2d_3[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 8, 8, 128)    0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
separable_conv2d_4 (SeparableCo (None, 8, 8, 128)    17664       activation_4[0][0]               
__________________________________________________________________________________________________
add_2 (Add)                     (None, 8, 8, 128)    0           add_1[0][0]                      
                                                                 separable_conv2d_4[0][0]         
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 8, 8, 128)    512         add_2[0][0]                      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 8, 8, 128)    0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
separable_conv2d_5 (SeparableCo (None, 4, 4, 256)    34176       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        separable_conv2d_5[0][0]         
__________________________________________________________________________________________________
separable_conv2d_7 (SeparableCo (None, 4, 4, 256)    33152       add_2[0][0]                      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 4, 4, 256)    0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 4, 4, 256)    1024        separable_conv2d_7[0][0]         
__________________________________________________________________________________________________
separable_conv2d_6 (SeparableCo (None, 4, 4, 256)    68096       activation_6[0][0]               
__________________________________________________________________________________________________
add_3 (Add)                     (None, 4, 4, 256)    0           batch_normalization_8[0][0]      
                                                                 separable_conv2d_6[0][0]         
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 4, 4, 256)    1024        add_3[0][0]                      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 4, 4, 256)    0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
separable_conv2d_8 (SeparableCo (None, 4, 4, 256)    68096       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 4, 4, 256)    1024        separable_conv2d_8[0][0]         
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 4, 4, 256)    0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
separable_conv2d_9 (SeparableCo (None, 4, 4, 256)    68096       activation_8[0][0]               
__________________________________________________________________________________________________
add_4 (Add)                     (None, 4, 4, 256)    0           add_3[0][0]                      
                                                                 separable_conv2d_9[0][0]         
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        add_4[0][0]                      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 4, 4, 256)    0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
separable_conv2d_10 (SeparableC (None, 2, 2, 512)    133888      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_10[0][0]        
__________________________________________________________________________________________________
separable_conv2d_12 (SeparableC (None, 2, 2, 512)    131840      add_4[0][0]                      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 2, 2, 512)    0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_12[0][0]        
__________________________________________________________________________________________________
separable_conv2d_11 (SeparableC (None, 2, 2, 512)    267264      activation_10[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 2, 2, 512)    0           batch_normalization_13[0][0]     
                                                                 separable_conv2d_11[0][0]        
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 2, 2, 512)    2048        add_5[0][0]                      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 2, 2, 512)    0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
separable_conv2d_13 (SeparableC (None, 2, 2, 512)    267264      activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 2, 2, 512)    2048        separable_conv2d_13[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 2, 2, 512)    0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
separable_conv2d_14 (SeparableC (None, 2, 2, 512)    267264      activation_12[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 2, 2, 512)    0           add_5[0][0]                      
                                                                 separable_conv2d_14[0][0]        
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 2, 2, 512)    2048        add_6[0][0]                      
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 2, 2, 512)    0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
separable_conv2d_15 (SeparableC (None, 1, 1, 1024)   529920      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_15[0][0]        
__________________________________________________________________________________________________
separable_conv2d_17 (SeparableC (None, 1, 1, 1024)   525824      add_6[0][0]                      
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_17[0][0]        
__________________________________________________________________________________________________
separable_conv2d_16 (SeparableC (None, 1, 1, 1024)   1058816     activation_14[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 1, 1, 1024)   0           batch_normalization_18[0][0]     
                                                                 separable_conv2d_16[0][0]        
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 1, 1, 1024)   4096        add_7[0][0]                      
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
separable_conv2d_18 (SeparableC (None, 1, 1, 1024)   1058816     activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 1, 1, 1024)   4096        separable_conv2d_18[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
separable_conv2d_19 (SeparableC (None, 1, 1, 1024)   1058816     activation_16[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 1, 1, 1024)   0           add_7[0][0]                      
                                                                 separable_conv2d_19[0][0]        
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 1, 1, 1024)   4096        add_8[0][0]                      
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 1, 1, 1024)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 1024)         0           activation_17[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           10250       global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 5,726,730
Trainable params: 5,707,274
Non-trainable params: 19,456
__________________________________________________________________________________________________




Epoch 1/50
Learning rate:  0.001
391/390 [==============================] - 41s 104ms/step - loss: 1.5741 - acc: 0.4383 - val_loss: 1.4594 - val_acc: 0.5048

Epoch 00001: val_acc improved from -inf to 0.50480, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.001.h5
Epoch 2/50
Learning rate:  0.001
391/390 [==============================] - 34s 88ms/step - loss: 1.1955 - acc: 0.5795 - val_loss: 1.2843 - val_acc: 0.5899

Epoch 00002: val_acc improved from 0.50480 to 0.58990, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.002.h5
Epoch 3/50
Learning rate:  0.001
391/390 [==============================] - 34s 88ms/step - loss: 0.9972 - acc: 0.6529 - val_loss: 1.0256 - val_acc: 0.6513

Epoch 00003: val_acc improved from 0.58990 to 0.65130, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.003.h5
Epoch 4/50
Learning rate:  0.001
391/390 [==============================] - 35s 88ms/step - loss: 0.8768 - acc: 0.6990 - val_loss: 0.9579 - val_acc: 0.6822

Epoch 00004: val_acc improved from 0.65130 to 0.68220, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.004.h5
Epoch 5/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.7848 - acc: 0.7291 - val_loss: 0.8276 - val_acc: 0.7247

Epoch 00005: val_acc improved from 0.68220 to 0.72470, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.005.h5
Epoch 6/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.7140 - acc: 0.7576 - val_loss: 0.9154 - val_acc: 0.7065

Epoch 00006: val_acc did not improve from 0.72470
Epoch 7/50
Learning rate:  0.001
391/390 [==============================] - 35s 88ms/step - loss: 0.6670 - acc: 0.7717 - val_loss: 0.7316 - val_acc: 0.7578

Epoch 00007: val_acc improved from 0.72470 to 0.75780, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.007.h5
Epoch 8/50
Learning rate:  0.001
391/390 [==============================] - 35s 88ms/step - loss: 0.6163 - acc: 0.7893 - val_loss: 0.6686 - val_acc: 0.7819

Epoch 00008: val_acc improved from 0.75780 to 0.78190, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.008.h5
Epoch 9/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5740 - acc: 0.8036 - val_loss: 0.7550 - val_acc: 0.7613

Epoch 00009: val_acc did not improve from 0.78190
Epoch 10/50
Learning rate:  0.001
391/390 [==============================] - 35s 89ms/step - loss: 0.5390 - acc: 0.8171 - val_loss: 0.6050 - val_acc: 0.8030

Epoch 00010: val_acc improved from 0.78190 to 0.80300, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.010.h5
Epoch 11/50
Learning rate:  0.001
391/390 [==============================] - 35s 88ms/step - loss: 0.5111 - acc: 0.8291 - val_loss: 0.6072 - val_acc: 0.8077

Epoch 00011: val_acc improved from 0.80300 to 0.80770, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.011.h5
Epoch 12/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.4022 - acc: 0.8665 - val_loss: 0.4762 - val_acc: 0.8425

Epoch 00012: val_acc improved from 0.80770 to 0.84250, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.012.h5
Epoch 13/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.3656 - acc: 0.8794 - val_loss: 0.4788 - val_acc: 0.8434

Epoch 00013: val_acc improved from 0.84250 to 0.84340, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.013.h5
Epoch 14/50
Learning rate:  0.0001
391/390 [==============================] - 34s 88ms/step - loss: 0.3596 - acc: 0.8816 - val_loss: 0.4754 - val_acc: 0.8445

Epoch 00014: val_acc improved from 0.84340 to 0.84450, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.014.h5
Epoch 15/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.3403 - acc: 0.8883 - val_loss: 0.4625 - val_acc: 0.8502

Epoch 00015: val_acc improved from 0.84450 to 0.85020, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.015.h5
Epoch 16/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.3289 - acc: 0.8927 - val_loss: 0.4620 - val_acc: 0.8517

Epoch 00016: val_acc improved from 0.85020 to 0.85170, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.016.h5
Epoch 17/50
Learning rate:  0.0001
391/390 [==============================] - 35s 88ms/step - loss: 0.3239 - acc: 0.8925 - val_loss: 0.4735 - val_acc: 0.8480

Epoch 00017: val_acc did not improve from 0.85170
Epoch 18/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.3112 - acc: 0.8968 - val_loss: 0.4750 - val_acc: 0.8489

Epoch 00018: val_acc did not improve from 0.85170
Epoch 19/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.3052 - acc: 0.8997 - val_loss: 0.4882 - val_acc: 0.8478

Epoch 00019: val_acc did not improve from 0.85170
Epoch 20/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2974 - acc: 0.9039 - val_loss: 0.4707 - val_acc: 0.8510

Epoch 00020: val_acc did not improve from 0.85170
Epoch 21/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2904 - acc: 0.9046 - val_loss: 0.4652 - val_acc: 0.8540

Epoch 00021: val_acc improved from 0.85170 to 0.85400, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.021.h5
Epoch 22/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2834 - acc: 0.9078 - val_loss: 0.4716 - val_acc: 0.8547

Epoch 00022: val_acc improved from 0.85400 to 0.85470, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.022.h5
Epoch 23/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2819 - acc: 0.9067 - val_loss: 0.4741 - val_acc: 0.8507

Epoch 00023: val_acc did not improve from 0.85470
Epoch 24/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2711 - acc: 0.9122 - val_loss: 0.4731 - val_acc: 0.8526

Epoch 00024: val_acc did not improve from 0.85470
Epoch 25/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2654 - acc: 0.9138 - val_loss: 0.4783 - val_acc: 0.8530

Epoch 00025: val_acc did not improve from 0.85470
Epoch 26/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2595 - acc: 0.9142 - val_loss: 0.4749 - val_acc: 0.8527

Epoch 00026: val_acc did not improve from 0.85470
Epoch 27/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2527 - acc: 0.9184 - val_loss: 0.4674 - val_acc: 0.8577

Epoch 00027: val_acc improved from 0.85470 to 0.85770, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.027.h5
Epoch 28/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2467 - acc: 0.9202 - val_loss: 0.4710 - val_acc: 0.8567

Epoch 00028: val_acc did not improve from 0.85770
Epoch 29/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2427 - acc: 0.9204 - val_loss: 0.4687 - val_acc: 0.8567

Epoch 00029: val_acc did not improve from 0.85770
Epoch 30/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2364 - acc: 0.9237 - val_loss: 0.4870 - val_acc: 0.8541

Epoch 00030: val_acc did not improve from 0.85770
Epoch 31/50
Learning rate:  0.0001
391/390 [==============================] - 35s 89ms/step - loss: 0.2370 - acc: 0.9229 - val_loss: 0.4774 - val_acc: 0.8577

Epoch 00031: val_acc did not improve from 0.85770
Epoch 32/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2203 - acc: 0.9296 - val_loss: 0.4708 - val_acc: 0.8577

Epoch 00032: val_acc did not improve from 0.85770
Epoch 33/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2167 - acc: 0.9301 - val_loss: 0.4697 - val_acc: 0.8586

Epoch 00033: val_acc improved from 0.85770 to 0.85860, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.033.h5
Epoch 34/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2166 - acc: 0.9318 - val_loss: 0.4667 - val_acc: 0.8596

Epoch 00034: val_acc improved from 0.85860 to 0.85960, saving model to C:\Users\aadur\saved_models\cifar10_ResNet18_model.034.h5
Epoch 35/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2144 - acc: 0.9326 - val_loss: 0.4669 - val_acc: 0.8581

Epoch 00035: val_acc did not improve from 0.85960
Epoch 36/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2164 - acc: 0.9319 - val_loss: 0.4680 - val_acc: 0.8584

Epoch 00036: val_acc did not improve from 0.85960
Epoch 37/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2128 - acc: 0.9319 - val_loss: 0.4693 - val_acc: 0.8571

Epoch 00037: val_acc did not improve from 0.85960
Epoch 38/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2101 - acc: 0.9337 - val_loss: 0.4672 - val_acc: 0.8586

Epoch 00038: val_acc did not improve from 0.85960
Epoch 39/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2101 - acc: 0.9339 - val_loss: 0.4714 - val_acc: 0.8581

Epoch 00039: val_acc did not improve from 0.85960
Epoch 40/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2142 - acc: 0.9321 - val_loss: 0.4694 - val_acc: 0.8575

Epoch 00040: val_acc did not improve from 0.85960
Epoch 41/50
Learning rate:  1e-05
391/390 [==============================] - 35s 89ms/step - loss: 0.2067 - acc: 0.9348 - val_loss: 0.4691 - val_acc: 0.8574

Epoch 00041: val_acc did not improve from 0.85960
Epoch 42/50
Learning rate:  1e-06
391/390 [==============================] - 35s 89ms/step - loss: 0.2055 - acc: 0.9355 - val_loss: 0.4682 - val_acc: 0.8575

Epoch 00042: val_acc did not improve from 0.85960
Epoch 43/50
Learning rate:  1e-06
391/390 [==============================] - 35s 89ms/step - loss: 0.2061 - acc: 0.9349 - val_loss: 0.4667 - val_acc: 0.8576

Epoch 00043: val_acc did not improve from 0.85960
Epoch 44/50
Learning rate:  1e-06
391/390 [==============================] - 35s 89ms/step - loss: 0.2057 - acc: 0.9354 - val_loss: 0.4667 - val_acc: 0.8575

Epoch 00044: val_acc did not improve from 0.85960
Epoch 45/50
Learning rate:  1e-06
391/390 [==============================] - 35s 89ms/step - loss: 0.2063 - acc: 0.9351 - val_loss: 0.4680 - val_acc: 0.8578

Epoch 00045: val_acc did not improve from 0.85960
Epoch 46/50
Learning rate:  1e-06
391/390 [==============================] - 35s 89ms/step - loss: 0.2054 - acc: 0.9351 - val_loss: 0.4676 - val_acc: 0.8581

Epoch 00046: val_acc did not improve from 0.85960
Epoch 47/50
Learning rate:  5e-07
391/390 [==============================] - 35s 89ms/step - loss: 0.2070 - acc: 0.9352 - val_loss: 0.4693 - val_acc: 0.8582

Epoch 00047: val_acc did not improve from 0.85960
Epoch 48/50
Learning rate:  5e-07
391/390 [==============================] - 35s 89ms/step - loss: 0.2041 - acc: 0.9357 - val_loss: 0.4684 - val_acc: 0.8582

Epoch 00048: val_acc did not improve from 0.85960
Epoch 49/50
Learning rate:  5e-07
391/390 [==============================] - 35s 89ms/step - loss: 0.2063 - acc: 0.9350 - val_loss: 0.4683 - val_acc: 0.8573

Epoch 00049: val_acc did not improve from 0.85960
Epoch 50/50
Learning rate:  5e-07
391/390 [==============================] - 35s 89ms/step - loss: 0.2058 - acc: 0.9342 - val_loss: 0.4690 - val_acc: 0.8574

Epoch 00050: val_acc did not improve from 0.85960
